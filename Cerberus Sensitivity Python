"""
Replicates key logic from the provided Power Automate Desktop (PAD) flow for Cerberus Sensitivity batching,
converting clipboard TSV input into batched parameter matrices for RIH and POOH with a max-iterations cap.

This Python version focuses on:
- Parsing the clipboard (or given text) with columns:
  [Pipe Fluid Density, Sleeve Number, Depth, Stretch FOE RIH, Streatch FOE POOH]
- Building non-empty lists for variables (PFD, Depth, FOE_RIH, FOE_POOH)
- Emulating PAD's batching algorithm to keep combinations <= max_iterations (default 200)
- Producing per-batch parameter grids for both RIH and POOH
- Optionally writing batch inputs to Excel sheets (no macros)

Usage (CLI):
    python cerberus_sensitivity_python.py --from-clipboard --out sensitivity_batches.xlsx
    python cerberus_sensitivity_python.py --file input.tsv --max-iterations 200

Programmatic:
    from cerberus_sensitivity_python import parse_tsv, build_batches, write_batches_to_excel
    df = parse_tsv(tsv_text)
    batches_rih = build_batches(df, mode="RIH", max_iterations=200)
    batches_pooh = build_batches(df, mode="POOH", max_iterations=200)
    write_batches_to_excel({"RIH": batches_rih, "POOH": batches_pooh}, "sensitivity_batches.xlsx")

Notes:
- This intentionally mirrors variable names and the batching logic from PAD where possible.
- Excel macro execution is not included; this produces clean inputs ready for downstream tools.
"""
from __future__ import annotations

import io
import argparse
import itertools
import os
import sys
from dataclasses import dataclass
from typing import List, Dict, Any, Optional
from pandas import DataFrame

try:
    import pandas as pd
except ImportError:  # lightweight fallback if pandas is not installed
    pd = None

try:
    import pyperclip
except Exception:
    pyperclip = None


@dataclass
class Inputs:
    pipe_fluid_density: List[Any]
    depth: List[Any]
    stretch_foe_rih: List[Any]
    stretch_foe_pooh: List[Any]


def parse_tsv(tsv_text: str) -> DataFrame:
    """Parse the PAD clipboard TSV into a DataFrame and normalize column names.
    Expects columns including (case-insensitive, minor typos tolerated):
      - Pipe Fluid Density
      - Sleeve Number (ignored here but kept in df)
      - Depth
      - Stretch FOE RIH
      - Streatch FOE POOH (typo preserved in PAD, normalize to Stretch FOE POOH)
    """
    if pd is None:
        raise RuntimeError("pandas is required to parse TSV. Please install pandas.")

    df = pd.read_csv(io.StringIO(tsv_text), sep="\t", engine="python")
    # Strip whitespace from headers
    df.columns = [str(c).strip() for c in df.columns]

    # Normalize the POOH typo if present
    cols = {c.lower(): c for c in df.columns}
    if "streatch foe pooh" in cols and "stretch foe pooh" not in cols:
        bad = cols["streatch foe pooh"]
        df.rename(columns={bad: "Stretch FOE POOH"}, inplace=True)

    return df


def _non_empty(series) -> List[Any]:
    if series is None:
        values = []
    elif hasattr(series, 'tolist'):
        values = series.tolist()
    elif isinstance(series, (list, tuple, set)):
        values = list(series)
    else:
        values = [series]
    return [x for x in values if (x is not None and str(x).strip() != '')]  # mirrors PAD IsNotEmpty


def extract_inputs(df: DataFrame) -> Inputs:
    pfd = _non_empty(df.get("Pipe Fluid Density", []))
    depth = _non_empty(df.get("Depth", []))
    foe_rih = _non_empty(df.get("Stretch FOE RIH", []))
    foe_pooh = _non_empty(df.get("Stretch FOE POOH", df.get("Streatch FOE POOH", [])))
    return Inputs(pfd, depth, foe_rih, foe_pooh)


@dataclass
class Batch:
    depth_values: List[Any]
    pipe_fluid_density: List[Any]
    foe_values: List[Any]
    # Derived sizes (for reference / validation)
    combinations: int
    start_index: int  # inclusive index in the full Depth list
    end_index: int    # inclusive index in the full Depth list


def _compute_depth_batching(depth_count: int, factor_count: int, max_iterations: int) -> Dict[str, Any]:
    """Mirror PAD logic to reduce the effective depth dimension so that
    (PFD.Count * FOE.Count * Depth_More_Count) <= max_iterations.

    Returns dict with:
      - depth_more_count (per batch)
      - num_time_run_model (number of batches)
      - depth_iteration_less_count (how many depth items are trimmed per batch)
    """
    count = 0
    total_iterations = factor_count * depth_count
    if total_iterations > max_iterations:
        while (factor_count * (depth_count - count)) > max_iterations and (depth_count - count) > 0:
            count += 1
    depth_iteration_less_count = count
    depth_more_count = max(depth_count - depth_iteration_less_count, 1)

    # Number of batches = ceil(depth_count / depth_more_count)
    num_time_run_model = depth_count // depth_more_count
    if num_time_run_model != (depth_count / depth_more_count):
        num_time_run_model += 1

    return {
        "depth_more_count": depth_more_count,
        "num_time_run_model": num_time_run_model,
        "depth_iteration_less_count": depth_iteration_less_count,
    }


def build_batches(df: DataFrame, mode: str = "RIH", max_iterations: int = 200) -> List[Batch]:
    """Create batches for RIH or POOH using the PAD batching algorithm.

    - mode: "RIH" uses Stretch FOE RIH; "POOH" uses Stretch FOE POOH.
    - max_iterations: cap for PFD * FOE * depth_per_batch.
    """
    if pd is None:
        raise RuntimeError("pandas is required to use build_batches. Please install pandas.")

    inputs = extract_inputs(df)
    if mode.upper() == "RIH":
        foe = inputs.stretch_foe_rih
    else:
        foe = inputs.stretch_foe_pooh

    pfd = inputs.pipe_fluid_density
    depth = inputs.depth

    factor_count = max(1, len(pfd)) * max(1, len(foe))
    batching = _compute_depth_batching(len(depth), factor_count, max_iterations)
    depth_more_count = batching["depth_more_count"]
    num_batches = batching["num_time_run_model"]

    batches: List[Batch] = []

    for batch_idx in range(1, num_batches + 1):  # PAD uses 1-based LoopIndex3
        # Determine slice bounds (PAD inclusive logic)
        # Depth_Count = min(Depth.Count - 1, Depth_More_Count * LoopIndex3 - 1)
        # Start = (LoopIndex3 - 1) * Depth_More_Count
        start = (batch_idx - 1) * depth_more_count
        end = min(len(depth) - 1, depth_more_count * batch_idx - 1)
        depth_values = depth[start : end + 1]

        combinations = len(depth_values) * max(1, len(pfd)) * max(1, len(foe))
        batches.append(
            Batch(
                depth_values=depth_values,
                pipe_fluid_density=pfd,
                foe_values=foe,
                combinations=combinations,
                start_index=start,
                end_index=end,
            )
        )

    return batches


def as_parameter_grid(batch: Batch) -> DataFrame:
    """Create a Cartesian product table like PAD's Parameter Matrix Wizard would submit.
    Columns: [Depth, Pipe Fluid Density, FOE]
    """
    if pd is None:
        raise RuntimeError("pandas is required to build the parameter grid. Please install pandas.")

    rows = list(itertools.product(batch.depth_values or [None], batch.pipe_fluid_density or [None], batch.foe_values or [None]))
    df = pd.DataFrame(rows, columns=["Depth", "Pipe Fluid Density", "FOE"])
    return df


def write_batches_to_excel(batches_by_mode: Dict[str, List[Batch]], out_path: str) -> None:
    """Write each batch grid to an Excel workbook. Sheets are named like
    'RIH_1', 'RIH_2', 'POOH_1', etc.
    """
    if pd is None:
        raise RuntimeError("pandas is required to write Excel files. Please install pandas.")

    with pd.ExcelWriter(out_path, engine="openpyxl") as xw:
        for mode, batches in batches_by_mode.items():
            for i, b in enumerate(batches, start=1):
                df_grid = as_parameter_grid(b)
                sheet = f"{mode.upper()}_{i}"
                df_grid.to_excel(xw, sheet_name=sheet, index=False)


def read_text(source_file: Optional[str], from_clipboard: bool) -> str:
    if source_file:
        with open(source_file, "r", encoding="utf-8") as f:
            return f.read()
    if from_clipboard:
        if pyperclip is None:
            raise RuntimeError("pyperclip is required for --from-clipboard. Install it or pass --file.")
        return pyperclip.paste()
    raise RuntimeError("Provide --file <path> or --from-clipboard.")


def main(argv: Optional[List[str]] = None) -> int:
    p = argparse.ArgumentParser(description="Cerberus Sensitivity PAD batching replicated in Python")
    p.add_argument("--file", help="Input TSV file exported from PAD clipboard")
    p.add_argument("--from-clipboard", action="store_true", help="Read TSV from clipboard")
    p.add_argument("--out", default="sensitivity_batches.xlsx", help="Excel workbook to write")
    p.add_argument("--max-iterations", type=int, default=200, help="Max combinations per batch")
    args = p.parse_args(argv)

    text = read_text(args.file, args.from_clipboard)

    if pd is None:
        print("ERROR: pandas is required. pip install pandas openpyxl pyperclip", file=sys.stderr)
        return 2

    # Parse & build
    df = parse_tsv(text)
    batches_rih = build_batches(df, mode="RIH", max_iterations=args.max_iterations)
    batches_pooh = build_batches(df, mode="POOH", max_iterations=args.max_iterations)

    # Write
    write_batches_to_excel({"RIH": batches_rih, "POOH": batches_pooh}, args.out)
    print(f"Wrote {len(batches_rih)} RIH and {len(batches_pooh)} POOH batches to: {args.out}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())



